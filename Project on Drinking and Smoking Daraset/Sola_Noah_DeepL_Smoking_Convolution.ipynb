{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "464586d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import pandas library\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91809203",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0148af1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset from a CSV file\n",
    "df = pd.read_csv(r'C:\\Users\\User\\smoking_driking_dataset_Ver01.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "074a0a61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sex                 False\n",
       "age                 False\n",
       "height              False\n",
       "weight              False\n",
       "waistline           False\n",
       "sight_left          False\n",
       "sight_right         False\n",
       "hear_left           False\n",
       "hear_right          False\n",
       "SBP                 False\n",
       "DBP                 False\n",
       "BLDS                False\n",
       "tot_chole           False\n",
       "HDL_chole           False\n",
       "LDL_chole           False\n",
       "triglyceride        False\n",
       "hemoglobin          False\n",
       "urine_protein       False\n",
       "serum_creatinine    False\n",
       "SGOT_AST            False\n",
       "SGOT_ALT            False\n",
       "gamma_GTP           False\n",
       "SMK_stat_type_cd    False\n",
       "DRK_YN              False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check for missing values in the dataset\n",
    "df.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "48a6f493",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with missing values in the 'SMK_stat_type_cd' column\n",
    "df.dropna(subset=['SMK_stat_type_cd'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "f69116f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with missing values in the 'DRK_YN' column\n",
    "df.dropna(subset=['DRK_YN'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0b9283c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove duplicate rows in the dataset\n",
    "df = df.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a4dfa80a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map categorical values to numerical values in 'sex', 'DRK_YN', and 'SMK_stat_type_cd' columns\n",
    "\n",
    "df[\"sex\"] = df[\"sex\"].map({\"Male\": 1, \"Female\": 0})\n",
    "df[\"DRK_YN\"] = df[\"DRK_YN\"].map({\"Y\": 1, \"N\": 0})\n",
    "\n",
    "smk_stat_mapping = {1: 0, 2: 1, 3: 2}\n",
    "df['SMK_stat_type_cd'] = df['SMK_stat_type_cd'].map(smk_stat_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9f35cf",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "label_encoder_2 = LabelEncoder()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81dd4e10",
   "metadata": {},
   "source": [
    "df['sex'] = label_encoder.fit_transform(df['sex'])\n",
    "\n",
    "df['DRK_YN'] = label_encoder_2.fit_transform(df['DRK_YN'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "56365838",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>991320.0</td>\n",
       "      <td>0.531008</td>\n",
       "      <td>0.499038</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>991320.0</td>\n",
       "      <td>47.614529</td>\n",
       "      <td>14.181346</td>\n",
       "      <td>20.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>height</th>\n",
       "      <td>991320.0</td>\n",
       "      <td>162.240563</td>\n",
       "      <td>9.282922</td>\n",
       "      <td>130.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>190.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight</th>\n",
       "      <td>991320.0</td>\n",
       "      <td>63.283884</td>\n",
       "      <td>12.514101</td>\n",
       "      <td>25.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>140.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>waistline</th>\n",
       "      <td>991320.0</td>\n",
       "      <td>81.233255</td>\n",
       "      <td>11.850296</td>\n",
       "      <td>8.0</td>\n",
       "      <td>74.1</td>\n",
       "      <td>81.0</td>\n",
       "      <td>87.8</td>\n",
       "      <td>999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sight_left</th>\n",
       "      <td>991320.0</td>\n",
       "      <td>0.980833</td>\n",
       "      <td>0.605954</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>9.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sight_right</th>\n",
       "      <td>991320.0</td>\n",
       "      <td>0.978428</td>\n",
       "      <td>0.604779</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>9.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hear_left</th>\n",
       "      <td>991320.0</td>\n",
       "      <td>1.031495</td>\n",
       "      <td>0.174652</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hear_right</th>\n",
       "      <td>991320.0</td>\n",
       "      <td>1.030476</td>\n",
       "      <td>0.171892</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SBP</th>\n",
       "      <td>991320.0</td>\n",
       "      <td>122.432360</td>\n",
       "      <td>14.543083</td>\n",
       "      <td>67.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>273.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DBP</th>\n",
       "      <td>991320.0</td>\n",
       "      <td>76.052549</td>\n",
       "      <td>9.889334</td>\n",
       "      <td>32.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BLDS</th>\n",
       "      <td>991320.0</td>\n",
       "      <td>100.424305</td>\n",
       "      <td>24.179852</td>\n",
       "      <td>25.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>852.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tot_chole</th>\n",
       "      <td>991320.0</td>\n",
       "      <td>195.556769</td>\n",
       "      <td>38.660092</td>\n",
       "      <td>30.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>2344.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HDL_chole</th>\n",
       "      <td>991320.0</td>\n",
       "      <td>56.936984</td>\n",
       "      <td>17.238578</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>8110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LDL_chole</th>\n",
       "      <td>991320.0</td>\n",
       "      <td>113.037429</td>\n",
       "      <td>35.842938</td>\n",
       "      <td>1.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>5119.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>triglyceride</th>\n",
       "      <td>991320.0</td>\n",
       "      <td>132.140030</td>\n",
       "      <td>102.194762</td>\n",
       "      <td>1.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>9490.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hemoglobin</th>\n",
       "      <td>991320.0</td>\n",
       "      <td>14.229810</td>\n",
       "      <td>1.584924</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.2</td>\n",
       "      <td>14.3</td>\n",
       "      <td>15.4</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>urine_protein</th>\n",
       "      <td>991320.0</td>\n",
       "      <td>1.094221</td>\n",
       "      <td>0.437719</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>serum_creatinine</th>\n",
       "      <td>991320.0</td>\n",
       "      <td>0.860467</td>\n",
       "      <td>0.480536</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGOT_AST</th>\n",
       "      <td>991320.0</td>\n",
       "      <td>25.989424</td>\n",
       "      <td>23.493668</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>9999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGOT_ALT</th>\n",
       "      <td>991320.0</td>\n",
       "      <td>25.755148</td>\n",
       "      <td>26.308910</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>7210.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gamma_GTP</th>\n",
       "      <td>991320.0</td>\n",
       "      <td>37.136152</td>\n",
       "      <td>50.423811</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>999.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMK_stat_type_cd</th>\n",
       "      <td>991320.0</td>\n",
       "      <td>0.608112</td>\n",
       "      <td>0.818504</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DRK_YN</th>\n",
       "      <td>991320.0</td>\n",
       "      <td>0.499814</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     count        mean         std    min    25%    50%  \\\n",
       "sex               991320.0    0.531008    0.499038    0.0    0.0    1.0   \n",
       "age               991320.0   47.614529   14.181346   20.0   35.0   45.0   \n",
       "height            991320.0  162.240563    9.282922  130.0  155.0  160.0   \n",
       "weight            991320.0   63.283884   12.514101   25.0   55.0   60.0   \n",
       "waistline         991320.0   81.233255   11.850296    8.0   74.1   81.0   \n",
       "sight_left        991320.0    0.980833    0.605954    0.1    0.7    1.0   \n",
       "sight_right       991320.0    0.978428    0.604779    0.1    0.7    1.0   \n",
       "hear_left         991320.0    1.031495    0.174652    1.0    1.0    1.0   \n",
       "hear_right        991320.0    1.030476    0.171892    1.0    1.0    1.0   \n",
       "SBP               991320.0  122.432360   14.543083   67.0  112.0  120.0   \n",
       "DBP               991320.0   76.052549    9.889334   32.0   70.0   76.0   \n",
       "BLDS              991320.0  100.424305   24.179852   25.0   88.0   96.0   \n",
       "tot_chole         991320.0  195.556769   38.660092   30.0  169.0  193.0   \n",
       "HDL_chole         991320.0   56.936984   17.238578    1.0   46.0   55.0   \n",
       "LDL_chole         991320.0  113.037429   35.842938    1.0   89.0  111.0   \n",
       "triglyceride      991320.0  132.140030  102.194762    1.0   73.0  106.0   \n",
       "hemoglobin        991320.0   14.229810    1.584924    1.0   13.2   14.3   \n",
       "urine_protein     991320.0    1.094221    0.437719    1.0    1.0    1.0   \n",
       "serum_creatinine  991320.0    0.860467    0.480536    0.1    0.7    0.8   \n",
       "SGOT_AST          991320.0   25.989424   23.493668    1.0   19.0   23.0   \n",
       "SGOT_ALT          991320.0   25.755148   26.308910    1.0   15.0   20.0   \n",
       "gamma_GTP         991320.0   37.136152   50.423811    1.0   16.0   23.0   \n",
       "SMK_stat_type_cd  991320.0    0.608112    0.818504    0.0    0.0    0.0   \n",
       "DRK_YN            991320.0    0.499814    0.500000    0.0    0.0    0.0   \n",
       "\n",
       "                    75%     max  \n",
       "sex                 1.0     1.0  \n",
       "age                60.0    85.0  \n",
       "height            170.0   190.0  \n",
       "weight             70.0   140.0  \n",
       "waistline          87.8   999.0  \n",
       "sight_left          1.2     9.9  \n",
       "sight_right         1.2     9.9  \n",
       "hear_left           1.0     2.0  \n",
       "hear_right          1.0     2.0  \n",
       "SBP               131.0   273.0  \n",
       "DBP                82.0   185.0  \n",
       "BLDS              105.0   852.0  \n",
       "tot_chole         219.0  2344.0  \n",
       "HDL_chole          66.0  8110.0  \n",
       "LDL_chole         135.0  5119.0  \n",
       "triglyceride      159.0  9490.0  \n",
       "hemoglobin         15.4    25.0  \n",
       "urine_protein       1.0     6.0  \n",
       "serum_creatinine    1.0    98.0  \n",
       "SGOT_AST           28.0  9999.0  \n",
       "SGOT_ALT           29.0  7210.0  \n",
       "gamma_GTP          39.0   999.0  \n",
       "SMK_stat_type_cd    1.0     2.0  \n",
       "DRK_YN              1.0     1.0  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b85e1d6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify columns with potential outliers\n",
    "possible_na = [\"waistline\", \"sight_left\", \"sight_right\", \"SGOT_AST\", \"SGOT_ALT\",\"gamma_GTP\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d990c4b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows with extreme values in specified columns\n",
    "for column in possible_na:\n",
    "    df = df[df[column] != df[column].max()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "52eff5e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>25%</th>\n",
       "      <th>50%</th>\n",
       "      <th>75%</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sex</th>\n",
       "      <td>985282.0</td>\n",
       "      <td>0.530715</td>\n",
       "      <td>0.499056</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>985282.0</td>\n",
       "      <td>47.534609</td>\n",
       "      <td>14.146148</td>\n",
       "      <td>20.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>85.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>height</th>\n",
       "      <td>985282.0</td>\n",
       "      <td>162.259673</td>\n",
       "      <td>9.278974</td>\n",
       "      <td>130.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>160.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>190.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight</th>\n",
       "      <td>985282.0</td>\n",
       "      <td>63.298396</td>\n",
       "      <td>12.518552</td>\n",
       "      <td>25.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>140.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>waistline</th>\n",
       "      <td>985282.0</td>\n",
       "      <td>81.166581</td>\n",
       "      <td>9.593149</td>\n",
       "      <td>8.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>87.6</td>\n",
       "      <td>149.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sight_left</th>\n",
       "      <td>985282.0</td>\n",
       "      <td>0.953213</td>\n",
       "      <td>0.341180</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sight_right</th>\n",
       "      <td>985282.0</td>\n",
       "      <td>0.950827</td>\n",
       "      <td>0.339704</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hear_left</th>\n",
       "      <td>985282.0</td>\n",
       "      <td>1.031064</td>\n",
       "      <td>0.173491</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hear_right</th>\n",
       "      <td>985282.0</td>\n",
       "      <td>1.030069</td>\n",
       "      <td>0.170776</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SBP</th>\n",
       "      <td>985282.0</td>\n",
       "      <td>122.400475</td>\n",
       "      <td>14.527969</td>\n",
       "      <td>70.0</td>\n",
       "      <td>112.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>131.0</td>\n",
       "      <td>273.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DBP</th>\n",
       "      <td>985282.0</td>\n",
       "      <td>76.046618</td>\n",
       "      <td>9.886885</td>\n",
       "      <td>33.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>82.0</td>\n",
       "      <td>185.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BLDS</th>\n",
       "      <td>985282.0</td>\n",
       "      <td>100.375971</td>\n",
       "      <td>24.106227</td>\n",
       "      <td>25.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>96.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>852.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tot_chole</th>\n",
       "      <td>985282.0</td>\n",
       "      <td>195.587281</td>\n",
       "      <td>38.620486</td>\n",
       "      <td>30.0</td>\n",
       "      <td>169.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>219.0</td>\n",
       "      <td>2344.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HDL_chole</th>\n",
       "      <td>985282.0</td>\n",
       "      <td>56.953538</td>\n",
       "      <td>17.248080</td>\n",
       "      <td>1.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>55.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>8110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LDL_chole</th>\n",
       "      <td>985282.0</td>\n",
       "      <td>113.067357</td>\n",
       "      <td>35.826749</td>\n",
       "      <td>1.0</td>\n",
       "      <td>89.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>135.0</td>\n",
       "      <td>5119.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>triglyceride</th>\n",
       "      <td>985282.0</td>\n",
       "      <td>132.057556</td>\n",
       "      <td>101.966841</td>\n",
       "      <td>1.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>106.0</td>\n",
       "      <td>159.0</td>\n",
       "      <td>9490.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hemoglobin</th>\n",
       "      <td>985282.0</td>\n",
       "      <td>14.231820</td>\n",
       "      <td>1.584264</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.2</td>\n",
       "      <td>14.3</td>\n",
       "      <td>15.4</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>urine_protein</th>\n",
       "      <td>985282.0</td>\n",
       "      <td>1.093690</td>\n",
       "      <td>0.436049</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>serum_creatinine</th>\n",
       "      <td>985282.0</td>\n",
       "      <td>0.860005</td>\n",
       "      <td>0.479292</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.8</td>\n",
       "      <td>1.0</td>\n",
       "      <td>98.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGOT_AST</th>\n",
       "      <td>985282.0</td>\n",
       "      <td>25.940487</td>\n",
       "      <td>21.065925</td>\n",
       "      <td>1.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>7000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SGOT_ALT</th>\n",
       "      <td>985282.0</td>\n",
       "      <td>25.737047</td>\n",
       "      <td>25.271785</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>4633.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gamma_GTP</th>\n",
       "      <td>985282.0</td>\n",
       "      <td>36.887071</td>\n",
       "      <td>48.111816</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>39.0</td>\n",
       "      <td>998.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SMK_stat_type_cd</th>\n",
       "      <td>985282.0</td>\n",
       "      <td>0.608173</td>\n",
       "      <td>0.818624</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DRK_YN</th>\n",
       "      <td>985282.0</td>\n",
       "      <td>0.500619</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     count        mean         std    min    25%    50%  \\\n",
       "sex               985282.0    0.530715    0.499056    0.0    0.0    1.0   \n",
       "age               985282.0   47.534609   14.146148   20.0   35.0   45.0   \n",
       "height            985282.0  162.259673    9.278974  130.0  155.0  160.0   \n",
       "weight            985282.0   63.298396   12.518552   25.0   55.0   60.0   \n",
       "waistline         985282.0   81.166581    9.593149    8.0   74.0   81.0   \n",
       "sight_left        985282.0    0.953213    0.341180    0.1    0.7    1.0   \n",
       "sight_right       985282.0    0.950827    0.339704    0.1    0.7    1.0   \n",
       "hear_left         985282.0    1.031064    0.173491    1.0    1.0    1.0   \n",
       "hear_right        985282.0    1.030069    0.170776    1.0    1.0    1.0   \n",
       "SBP               985282.0  122.400475   14.527969   70.0  112.0  120.0   \n",
       "DBP               985282.0   76.046618    9.886885   33.0   70.0   76.0   \n",
       "BLDS              985282.0  100.375971   24.106227   25.0   88.0   96.0   \n",
       "tot_chole         985282.0  195.587281   38.620486   30.0  169.0  193.0   \n",
       "HDL_chole         985282.0   56.953538   17.248080    1.0   46.0   55.0   \n",
       "LDL_chole         985282.0  113.067357   35.826749    1.0   89.0  111.0   \n",
       "triglyceride      985282.0  132.057556  101.966841    1.0   73.0  106.0   \n",
       "hemoglobin        985282.0   14.231820    1.584264    1.0   13.2   14.3   \n",
       "urine_protein     985282.0    1.093690    0.436049    1.0    1.0    1.0   \n",
       "serum_creatinine  985282.0    0.860005    0.479292    0.1    0.7    0.8   \n",
       "SGOT_AST          985282.0   25.940487   21.065925    1.0   19.0   23.0   \n",
       "SGOT_ALT          985282.0   25.737047   25.271785    1.0   15.0   20.0   \n",
       "gamma_GTP         985282.0   36.887071   48.111816    1.0   16.0   23.0   \n",
       "SMK_stat_type_cd  985282.0    0.608173    0.818624    0.0    0.0    0.0   \n",
       "DRK_YN            985282.0    0.500619    0.500000    0.0    0.0    1.0   \n",
       "\n",
       "                    75%     max  \n",
       "sex                 1.0     1.0  \n",
       "age                60.0    85.0  \n",
       "height            170.0   190.0  \n",
       "weight             70.0   140.0  \n",
       "waistline          87.6   149.1  \n",
       "sight_left          1.2     2.5  \n",
       "sight_right         1.2     2.5  \n",
       "hear_left           1.0     2.0  \n",
       "hear_right          1.0     2.0  \n",
       "SBP               131.0   273.0  \n",
       "DBP                82.0   185.0  \n",
       "BLDS              105.0   852.0  \n",
       "tot_chole         219.0  2344.0  \n",
       "HDL_chole          66.0  8110.0  \n",
       "LDL_chole         135.0  5119.0  \n",
       "triglyceride      159.0  9490.0  \n",
       "hemoglobin         15.4    25.0  \n",
       "urine_protein       1.0     6.0  \n",
       "serum_creatinine    1.0    98.0  \n",
       "SGOT_AST           28.0  7000.0  \n",
       "SGOT_ALT           29.0  4633.0  \n",
       "gamma_GTP          39.0   998.0  \n",
       "SMK_stat_type_cd    1.0     2.0  \n",
       "DRK_YN              1.0     1.0  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Display updated summary statistics\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "414e9622",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of numerical columns for outlier detection and handling\n",
    "num_cols = ['age', 'height', 'weight', 'waistline', 'sight_left', 'sight_right', 'SBP', 'DBP', 'BLDS', 'tot_chole', 'HDL_chole', 'LDL_chole', 'triglyceride', 'hemoglobin', 'serum_creatinine', 'SGOT_AST', 'SGOT_ALT', 'gamma_GTP']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "29513a93",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight\n",
      "waistline\n",
      "SBP\n",
      "DBP\n",
      "BLDS\n",
      "tot_chole\n",
      "HDL_chole\n",
      "LDL_chole\n",
      "triglyceride\n",
      "hemoglobin\n",
      "serum_creatinine\n",
      "SGOT_AST\n",
      "SGOT_ALT\n",
      "gamma_GTP\n"
     ]
    }
   ],
   "source": [
    "# Function to calculate outlier thresholds for a column\n",
    "def outlier_thresholds(dataframe, col_name, q1=0.05, q3=0.90):\n",
    "    \"\"\"\n",
    "    Calculate lower and upper thresholds for detecting outliers in a column of a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        dataframe (pd.DataFrame): The DataFrame containing the data.\n",
    "        col_name (str): The name of the column for which outliers will be detected.\n",
    "        q1 (float): The lower quantile value to determine the lower threshold.\n",
    "        q3 (float): The upper quantile value to determine the upper threshold.\n",
    "\n",
    "    Returns:\n",
    "        float: The lower threshold value.\n",
    "        float: The upper threshold value.\n",
    "    \"\"\"\n",
    "    quartile1 = dataframe[col_name].quantile(q1)\n",
    "    quartile3 = dataframe[col_name].quantile(q3)\n",
    "    interquantile_range = quartile3 - quartile1\n",
    "    up_limit = quartile3 + 1.5 * interquantile_range\n",
    "    low_limit = quartile1 - 1.5 * interquantile_range\n",
    "    return low_limit, up_limit\n",
    "\n",
    "# Function to check for outliers in a column\n",
    "def check_outlier(df, col_name):\n",
    "    \"\"\"\n",
    "    Check for outliers in a column of a DataFrame based on specified thresholds.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): The DataFrame containing the data.\n",
    "        col_name (str): The name of the column to check for outliers.\n",
    "\n",
    "    Returns:\n",
    "        bool: True if outliers are found, False if not.\n",
    "    \"\"\"\n",
    "    low_limit, up_limit = outlier_thresholds(df, col_name)\n",
    "    if df[(df[col_name] > up_limit) | (df[col_name] < low_limit)].any(axis=None):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "# List to store columns with outliers\n",
    "outlier_cols = []\n",
    "\n",
    "# Check for outliers in numerical columns\n",
    "for col in num_cols:\n",
    "    if check_outlier(df, col):\n",
    "        outlier_cols.append(col)\n",
    "        print(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bcb933d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to apply Winsorization to a column\n",
    "def winsorize(dataframe, col_name, lower_quantile=0.05, upper_quantile=0.95):\n",
    "    \"\"\"\n",
    "    Apply Winsorization to a specific column in a DataFrame.\n",
    "\n",
    "    Args:\n",
    "        dataframe (pd.DataFrame): The DataFrame containing the data.\n",
    "        col_name (str): The name of the column to winsorize.\n",
    "        lower_quantile (float): The lower quantile value for determining the lower limit.\n",
    "        upper_quantile (float): The upper quantile value for determining the upper limit.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    lower_limit, upper_limit = outlier_thresholds(dataframe, col_name, q1=lower_quantile, q3=upper_quantile)\n",
    "    dataframe[col_name] = dataframe[col_name].apply(lambda x: lower_limit if x < lower_limit else (upper_limit if x > upper_limit else x))\n",
    "\n",
    "\n",
    "# Defining lower and upper quantiles for Winsorization\n",
    "lower_quantile = 0.05\n",
    "upper_quantile = 0.90\n",
    "\n",
    "# Apply Winsorization to columns with outliers\n",
    "for col in outlier_cols:\n",
    "    winsorize(df, col, lower_quantile, upper_quantile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "d831974b",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 143. MiB for an array with shape (19, 985282) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[49], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Display updated summary statistics after Winsorization\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m df\u001b[38;5;241m.\u001b[39mdescribe()\u001b[38;5;241m.\u001b[39mT\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:10819\u001b[0m, in \u001b[0;36mNDFrame.describe\u001b[1;34m(self, percentiles, include, exclude)\u001b[0m\n\u001b[0;32m  10577\u001b[0m \u001b[38;5;129m@final\u001b[39m\n\u001b[0;32m  10578\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdescribe\u001b[39m(\n\u001b[0;32m  10579\u001b[0m     \u001b[38;5;28mself\u001b[39m: NDFrameT,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  10582\u001b[0m     exclude\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m  10583\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m NDFrameT:\n\u001b[0;32m  10584\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m  10585\u001b[0m \u001b[38;5;124;03m    Generate descriptive statistics.\u001b[39;00m\n\u001b[0;32m  10586\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m  10817\u001b[0m \u001b[38;5;124;03m    max            NaN      3.0\u001b[39;00m\n\u001b[0;32m  10818\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m> 10819\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m describe_ndframe(\n\u001b[0;32m  10820\u001b[0m         obj\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m  10821\u001b[0m         include\u001b[38;5;241m=\u001b[39minclude,\n\u001b[0;32m  10822\u001b[0m         exclude\u001b[38;5;241m=\u001b[39mexclude,\n\u001b[0;32m  10823\u001b[0m         percentiles\u001b[38;5;241m=\u001b[39mpercentiles,\n\u001b[0;32m  10824\u001b[0m     )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\methods\\describe.py:94\u001b[0m, in \u001b[0;36mdescribe_ndframe\u001b[1;34m(obj, include, exclude, percentiles)\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     88\u001b[0m     describer \u001b[38;5;241m=\u001b[39m DataFrameDescriber(\n\u001b[0;32m     89\u001b[0m         obj\u001b[38;5;241m=\u001b[39mcast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDataFrame\u001b[39m\u001b[38;5;124m\"\u001b[39m, obj),\n\u001b[0;32m     90\u001b[0m         include\u001b[38;5;241m=\u001b[39minclude,\n\u001b[0;32m     91\u001b[0m         exclude\u001b[38;5;241m=\u001b[39mexclude,\n\u001b[0;32m     92\u001b[0m     )\n\u001b[1;32m---> 94\u001b[0m result \u001b[38;5;241m=\u001b[39m describer\u001b[38;5;241m.\u001b[39mdescribe(percentiles\u001b[38;5;241m=\u001b[39mpercentiles)\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m cast(NDFrameT, result)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\methods\\describe.py:162\u001b[0m, in \u001b[0;36mDataFrameDescriber.describe\u001b[1;34m(self, percentiles)\u001b[0m\n\u001b[0;32m    161\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdescribe\u001b[39m(\u001b[38;5;28mself\u001b[39m, percentiles: Sequence[\u001b[38;5;28mfloat\u001b[39m] \u001b[38;5;241m|\u001b[39m np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[1;32m--> 162\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_data()\n\u001b[0;32m    164\u001b[0m     ldesc: \u001b[38;5;28mlist\u001b[39m[Series] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    165\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m _, series \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\methods\\describe.py:183\u001b[0m, in \u001b[0;36mDataFrameDescriber._select_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    180\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minclude \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexclude \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;66;03m# when some numerics are found, keep only numerics\u001b[39;00m\n\u001b[0;32m    182\u001b[0m     default_include: \u001b[38;5;28mlist\u001b[39m[npt\u001b[38;5;241m.\u001b[39mDTypeLike] \u001b[38;5;241m=\u001b[39m [np\u001b[38;5;241m.\u001b[39mnumber, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdatetime\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m--> 183\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\u001b[38;5;241m.\u001b[39mselect_dtypes(include\u001b[38;5;241m=\u001b[39mdefault_include)\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data\u001b[38;5;241m.\u001b[39mcolumns) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    185\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobj\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:4708\u001b[0m, in \u001b[0;36mDataFrame.select_dtypes\u001b[1;34m(self, include, exclude)\u001b[0m\n\u001b[0;32m   4704\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m   4706\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m-> 4708\u001b[0m mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39m_get_data_subset(predicate)\u001b[38;5;241m.\u001b[39mcopy(deep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m   4709\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)(mgr)\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:664\u001b[0m, in \u001b[0;36mBaseBlockManager.copy\u001b[1;34m(self, deep)\u001b[0m\n\u001b[0;32m    661\u001b[0m         res\u001b[38;5;241m.\u001b[39m_blklocs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_blklocs\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m    663\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m deep:\n\u001b[1;32m--> 664\u001b[0m     res\u001b[38;5;241m.\u001b[39m_consolidate_inplace()\n\u001b[0;32m    665\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m res\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:1829\u001b[0m, in \u001b[0;36mBlockManager._consolidate_inplace\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1823\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_consolidate_inplace\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   1824\u001b[0m     \u001b[38;5;66;03m# In general, _consolidate_inplace should only be called via\u001b[39;00m\n\u001b[0;32m   1825\u001b[0m     \u001b[38;5;66;03m#  DataFrame._consolidate_inplace, otherwise we will fail to invalidate\u001b[39;00m\n\u001b[0;32m   1826\u001b[0m     \u001b[38;5;66;03m#  the DataFrame's _item_cache. The exception is for newly-created\u001b[39;00m\n\u001b[0;32m   1827\u001b[0m     \u001b[38;5;66;03m#  BlockManager objects not yet attached to a DataFrame.\u001b[39;00m\n\u001b[0;32m   1828\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_consolidated():\n\u001b[1;32m-> 1829\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks \u001b[38;5;241m=\u001b[39m _consolidate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks)\n\u001b[0;32m   1830\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_is_consolidated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[0;32m   1831\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_known_consolidated \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2272\u001b[0m, in \u001b[0;36m_consolidate\u001b[1;34m(blocks)\u001b[0m\n\u001b[0;32m   2270\u001b[0m new_blocks: \u001b[38;5;28mlist\u001b[39m[Block] \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m   2271\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m (_can_consolidate, dtype), group_blocks \u001b[38;5;129;01min\u001b[39;00m grouper:\n\u001b[1;32m-> 2272\u001b[0m     merged_blocks, _ \u001b[38;5;241m=\u001b[39m _merge_blocks(\n\u001b[0;32m   2273\u001b[0m         \u001b[38;5;28mlist\u001b[39m(group_blocks), dtype\u001b[38;5;241m=\u001b[39mdtype, can_consolidate\u001b[38;5;241m=\u001b[39m_can_consolidate\n\u001b[0;32m   2274\u001b[0m     )\n\u001b[0;32m   2275\u001b[0m     new_blocks \u001b[38;5;241m=\u001b[39m extend_blocks(merged_blocks, new_blocks)\n\u001b[0;32m   2276\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtuple\u001b[39m(new_blocks)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2304\u001b[0m, in \u001b[0;36m_merge_blocks\u001b[1;34m(blocks, dtype, can_consolidate)\u001b[0m\n\u001b[0;32m   2301\u001b[0m     new_values \u001b[38;5;241m=\u001b[39m bvals2[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_concat_same_type(bvals2, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m   2303\u001b[0m argsort \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margsort(new_mgr_locs)\n\u001b[1;32m-> 2304\u001b[0m new_values \u001b[38;5;241m=\u001b[39m new_values[argsort]\n\u001b[0;32m   2305\u001b[0m new_mgr_locs \u001b[38;5;241m=\u001b[39m new_mgr_locs[argsort]\n\u001b[0;32m   2307\u001b[0m bp \u001b[38;5;241m=\u001b[39m BlockPlacement(new_mgr_locs)\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 143. MiB for an array with shape (19, 985282) and data type float64"
     ]
    }
   ],
   "source": [
    "# Display updated summary statistics after Winsorization\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9c2045",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale numerical features using Min-Max scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "#columns_to_scale = df.columns.difference([\"DRK_YN\", \"SMK_stat_type_cd\"])\n",
    "columns_to_scale = df.columns.difference([\"SMK_stat_type_cd\"])\n",
    "\n",
    "df_input = df[columns_to_scale]\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "\n",
    "scaled_data = scaler.fit_transform(df_input)\n",
    "scaled_data = pd.DataFrame(scaled_data, columns=columns_to_scale)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97ea911",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display shape and summary statistics of scaled data\n",
    "scaled_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54dadff",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled_data.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc1988f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the target column for classification (e.g.,'SMK_stat_type_cd')\n",
    "df_out_smoke = df['SMK_stat_type_cd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ced2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the target column for classification (e.g., 'DRK_YN')\n",
    "#df_out_drink = df['DRK_YN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d470910a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape target column for one-hot encoding\n",
    "df_out_smoke_2 = df_out_smoke.values.reshape(-1, 1)\n",
    "#df_out_drink_2 = df_out_drink.values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b15147f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode the target column using scikit-learn's OneHotEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe_smoke = OneHotEncoder(handle_unknown='ignore', sparse=False).fit(df_out_smoke_2.reshape(-1, 1))\n",
    "\n",
    "#ohe_drink = OneHotEncoder(handle_unknown='ignore', sparse=False).fit(df_out_drink_2.reshape(-1, 1))\n",
    "\n",
    "df_out_smoke_2 = ohe_smoke.transform(df_out_smoke_2)\n",
    "\n",
    "#df_out_drink_2 = ohe_drink.transform(df_out_drink_2)\n",
    "\n",
    "# Display shape of the one-hot encoded target columnÂµ*****************\n",
    "#df_out_drink_2.shape\n",
    "df_out_smoke_2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10f06c82",
   "metadata": {},
   "source": [
    "# PyTorch Dataset and DataLoader Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb151f02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a custom dataset class for PyTorch\n",
    "from torch.utils.data import Dataset\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df_input, df_out):\n",
    "        # convert into PyTorch tensors and remember them\n",
    "        self.df_input = torch.Tensor(df_input)\n",
    "        self.df_out = torch.Tensor(df_out)\n",
    " \n",
    "    def __len__(self):\n",
    "        # this should return the size of the dataset\n",
    "        return len(self.df_out)\n",
    " \n",
    "    def __getitem__(self, idx):\n",
    "        # this should return one sample from the dataset\n",
    "        input_data = self.df_input[idx]\n",
    "        output_data = self.df_out[idx]\n",
    "        return input_data, output_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8fb9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set up DataLoader for data set\n",
    "import torch\n",
    "\n",
    "# Convert scaled input data and one-hot encoded target data to PyTorch tensors\n",
    "df_input_2 = torch.tensor(scaled_data.values, dtype=torch.float32)\n",
    "\n",
    "df_out_smoke_2 = torch.tensor(df_out_smoke_2, dtype=torch.float32)\n",
    "#df_out_drink_2 = torch.tensor(df_out_drink_2, dtype=torch.float32)\n",
    "\n",
    "# Create instances of the custom dataset class for training, validation, and testing\n",
    "dataset = CustomDataset(df_input_2, df_out_smoke_2)\n",
    "#dataset = CustomDataset(df_input_2, df_out_drink_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "820b19bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into training, validation, and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "val_test_data, train_data = train_test_split(dataset, test_size = 0.6, random_state=1)\n",
    "\n",
    "val_data, test_data = train_test_split(val_test_data, test_size = 0.5, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ca2202",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create DataLoader instances for the datasets\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "batch_size = 50\n",
    "\n",
    "train_loader = DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "val_loader = DataLoader(val_data, shuffle=False, batch_size=batch_size)\n",
    "test_loader = DataLoader(test_data, shuffle=False, batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07ece1b9",
   "metadata": {},
   "source": [
    "# Neural Network Model Definition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a8aa61",
   "metadata": {},
   "source": [
    "# Define the neural network architecture using PyTorch\n",
    "import torch.nn as nn\n",
    "class DrinkerSmokerClass(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "\n",
    "        self.fc1 = nn.Linear(23, 64)\n",
    "        self.batchnorm_fc1 = nn.BatchNorm1d(64)\n",
    "        \n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.batchnorm_fc2 = nn.BatchNorm1d(64)\n",
    "        \n",
    "        self.fc3 = nn.Linear(64, 23)\n",
    "        self.batchnorm_fc3 = nn.BatchNorm1d(23)\n",
    "\n",
    "        self.fc4 = nn.Linear(23, 2)\n",
    "        self.batchnorm_fc4 = nn.BatchNorm1d(2)\n",
    "        \n",
    "        self.fc5 = nn.Linear(23, 2)\n",
    "        self.batchnorm_fc5 = nn.BatchNorm1d(2)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "\n",
    "        # self.af = nn.ReLU()\n",
    "        # self.af = nn.Sigmoid()\n",
    "        self.af_2 = nn.Tanh()\n",
    "        #self.af = nn.LeakyReLU()\n",
    "        self.af = nn.PReLU()\n",
    "        #self.af = nn.SELU()\n",
    "        \n",
    "        \n",
    "        # self.af_out = nn.Softmax(dim=1)\n",
    "        self.af_out = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.batchnorm_fc1(x)\n",
    "        #x = self.dropout(x)\n",
    "        x = self.af(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.batchnorm_fc2(x)\n",
    "        #x = self.dropout(x)\n",
    "        x = self.af(x)\n",
    "        x = self.fc3(x)\n",
    "        x = self.batchnorm_fc3(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.af_2(x)\n",
    "        x = self.fc4(x)\n",
    "        x = self.batchnorm_fc4(x)\n",
    "        x = self.af_out(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ccd9ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "class DrinkerSmokerClass(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.conv1 = nn.Conv1d(in_channels=1, out_channels=16, kernel_size=1, stride=1)\n",
    "        self.batchnorm_conv1 = nn.BatchNorm1d(16)\n",
    "        \n",
    "        self.conv2 = nn.Conv1d(in_channels=16, out_channels=32, kernel_size=1, stride=1)\n",
    "        self.batchnorm_conv2 = nn.BatchNorm1d(32)\n",
    "        \n",
    "        self.conv3 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=2, stride=3)\n",
    "        self.batchnorm_conv3 = nn.BatchNorm1d(64)\n",
    "        \n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        self.fc1 = nn.Linear(512, 16)\n",
    "        self.batchnorm_fc1 = nn.BatchNorm1d(16)\n",
    "        \n",
    "        self.fc2 = nn.Linear(16, 3)\n",
    "        self.batchnorm_fc2 = nn.BatchNorm1d(3)\n",
    "        \n",
    "        #self.fc3 = nn.Linear(16, 3)\n",
    "        #self.batchnorm_fc3 = nn.BatchNorm1d(3)\n",
    "\n",
    "        self.af = nn.PReLU()\n",
    "        \n",
    "        self.af_out = nn.Softmax(dim=1)\n",
    "        #self.af_out = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.batchnorm_conv1(x)\n",
    "        x = self.af(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.batchnorm_conv2(x)\n",
    "        x = self.af(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.batchnorm_conv3(x)\n",
    "        x = self.af(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.batchnorm_fc1(x)\n",
    "        x = self.af(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.batchnorm_fc2(x)\n",
    "        x = self.af_out(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2477fd3c",
   "metadata": {},
   "source": [
    "# Set up early stopping with model saving\n",
    "class EarlyStoppingWithCheckpoint:\n",
    "    def __init__(self, patience=5, delta=0, verbose=False, checkpoint_path='best_model.pth'):\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.checkpoint_path = checkpoint_path\n",
    "\n",
    "    def __call__(self, val_loss, model):\n",
    "        score = -val_loss\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "                \n",
    "        elif score < self.best_score + self.delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f'Epoch {epoch + 1}, Validation loss did not decrease ({val_loss:.6f}), Counter: {self.counter}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.counter = 0\n",
    "            self.save_checkpoint(val_loss, model)\n",
    "\n",
    "        return self.early_stop\n",
    "\n",
    "    def save_checkpoint(self, val_loss, model):\n",
    "        if self.verbose:\n",
    "            print(f'Validation loss decreased ({val_loss:.6f} --> saving model)')\n",
    "        torch.save(model.state_dict(), self.checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "981c9745",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up early stopping with model saving\n",
    "class EarlyStoppingWithCheckpoint:\n",
    "    def __init__(self, patience=5, delta=0, verbose=False, checkpoint_path='best_model.pth'):\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.verbose = verbose\n",
    "        self.counter = 0\n",
    "        self.best_score = None\n",
    "        self.early_stop = False\n",
    "        self.checkpoint_path = checkpoint_path\n",
    "\n",
    "    def __call__(self, val_accuracy, model):\n",
    "        score = val_accuracy\n",
    "\n",
    "        if self.best_score is None:\n",
    "            self.best_score = score\n",
    "            self.save_checkpoint(val_accuracy, model)\n",
    "                \n",
    "        elif score < self.best_score - self.delta:\n",
    "            self.counter += 1\n",
    "            if self.verbose:\n",
    "                print(f'Epoch {epoch + 1}, Validation accuracy did not increase ({val_accuracy:.4f}), Counter: {self.counter}')\n",
    "            if self.counter >= self.patience:\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_score = score\n",
    "            self.counter = 0\n",
    "            self.save_checkpoint(val_accuracy, model)\n",
    "\n",
    "        return self.early_stop\n",
    "\n",
    "    def save_checkpoint(self, val_accuracy, model):\n",
    "        if self.verbose:\n",
    "            print(f'Validation accuracy increased ({val_accuracy:.4f} --> saving model)')\n",
    "        torch.save(model.state_dict(), self.checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0b02c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "n_epochs = 20\n",
    "\n",
    "model = DrinkerSmokerClass()\n",
    "\n",
    "#loss_fn = nn.BCELoss()\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0002)\n",
    "#optimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=0.002)\n",
    "\n",
    "# Set up early stopping\n",
    "early_stopping = EarlyStoppingWithCheckpoint(patience=3, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc28b65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# import EarlyStopping\n",
    "# from pytorchtools import EarlyStopping\n",
    "\n",
    "best_acc = - np.inf   # init to negative infinity\n",
    "best_weights = None\n",
    "patience = 3\n",
    "\n",
    "train_loss_hist = []\n",
    "train_acc_hist = []\n",
    "\n",
    "val_loss_hist = []\n",
    "val_acc_hist = []\n",
    "\n",
    "l1_lambda = 0.001\n",
    "\n",
    "# initialize the early_stopping object\n",
    "# early_stopping = EarlyStopping(patience=patience, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f980fd0",
   "metadata": {},
   "source": [
    "print(y_pred_train.size())\n",
    "print(y_batch_train.size())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23927b1b",
   "metadata": {},
   "source": [
    "# Training and Evaluation Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c2731c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training loop\n",
    "from tqdm import tqdm\n",
    "import copy\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(n_epochs):\n",
    "    # set model in training mode and run through each batch\n",
    "    model.train()\n",
    "    running_train_loss = 0\n",
    "    running_train_acc = 0\n",
    "    progress_bar_train = tqdm(enumerate(train_loader))\n",
    "    \n",
    "    for index, (X_batch_train, y_batch_train) in progress_bar_train:\n",
    "        optimizer.zero_grad()\n",
    "        # forward pass\n",
    "        y_pred_train = model(X_batch_train.unsqueeze(1))\n",
    "        #y_pred_train = model(X_batch_train)\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        l1_reg = 0\n",
    "        for param in model.parameters():\n",
    "            l1_reg += torch.abs(param).sum()\n",
    "            loss_train = loss_fn(y_pred_train, y_batch_train) + l1_lambda*l1_reg\n",
    "        \"\"\"\n",
    "            \n",
    "        loss_train = loss_fn(y_pred_train, y_batch_train)\n",
    "        running_train_loss += loss_train.item()\n",
    "        # backward pass\n",
    "        optimizer.zero_grad()\n",
    "        loss_train.backward()\n",
    "        # update weights\n",
    "        optimizer.step()\n",
    "        \n",
    "        # compute accuracy metrics\n",
    "        correct_pred_train = (torch.argmax(y_pred_train, 1) == torch.argmax(y_batch_train, 1)).float()\n",
    "        acc_train = correct_pred_train.sum() / len(correct_pred_train)\n",
    "        running_train_acc += acc_train\n",
    "         \n",
    "        \n",
    "        progress_bar_train.set_description(f'Epoch [{epoch+1}/{n_epochs}] Training Loss: {running_train_loss/(index+1):.4f} Training accuracy: {(running_train_acc/(index+1))*100:.2f}%')\n",
    "    \n",
    "     # store metrics\n",
    "    train_loss_hist.append(running_train_loss/(index+1))\n",
    "    train_acc_hist.append(running_train_acc/(index+1))\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    running_val_loss = 0\n",
    "    running_val_acc = 0\n",
    "    progress_bar_val = tqdm(enumerate(val_loader)) \n",
    "    for index, (X_batch_val, y_batch_val) in progress_bar_val:\n",
    "        with torch.no_grad():\n",
    "            y_pred_val = model(X_batch_val.unsqueeze(1))\n",
    "            #y_pred_val = model(X_batch_val)\n",
    "            val_test = loss_fn(y_pred_val, y_batch_val)\n",
    "            running_val_loss += val_test.item()\n",
    "            \n",
    "            # Calculate accuracy metric\n",
    "            correct_pred_val = (torch.argmax(y_pred_val, 1) == torch.argmax(y_batch_val, 1)).float()\n",
    "            acc_val = correct_pred_val.sum() / len(correct_pred_val)\n",
    "            running_val_acc += acc_val\n",
    "            \n",
    "            progress_bar_val.set_description(f'Epoch [{epoch+1}/{n_epochs}] Validation Loss: {running_val_loss/(index+1):.4f} Validation accuracy: {(running_val_acc/(index+1))*100:.2f}%')\n",
    "        \n",
    "    val_loss_hist.append(running_val_loss/(index+1))\n",
    "    val_acc_hist.append(running_val_acc/(index+1))\n",
    "    \n",
    "    # Early stopping check\n",
    "    if early_stopping(running_val_acc/(index+1), model):\n",
    "        print(f'Early stopping after {early_stopping.counter} epochs without improvement in accuracy.')\n",
    "        break\n",
    " \n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0871cb08",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the best model\n",
    "best_model = DrinkerSmokerClass()\n",
    "best_model.load_state_dict(torch.load('best_model.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dff4f1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "test_loss_hist = []\n",
    "test_acc_hist = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d1cd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the best model on the test set\n",
    "model.eval()\n",
    "running_test_loss = 0\n",
    "running_test_acc = 0\n",
    "progress_bar_test = tqdm(enumerate(test_loader)) \n",
    "for index, (X_batch_test, y_batch_test) in progress_bar_test:\n",
    "    with torch.no_grad():\n",
    "        y_pred_test = best_model(X_batch_test.unsqueeze(1))\n",
    "        #y_pred_test = best_model(X_batch_test)\n",
    "        loss_test = loss_fn(y_pred_test, y_batch_test)\n",
    "        running_test_loss += loss_test.item()\n",
    "            \n",
    "        # Calculate accuracy metric\n",
    "        correct_pred_test = (torch.argmax(y_pred_test, 1) == torch.argmax(y_batch_test, 1)).float()\n",
    "        acc_test = correct_pred_test.sum() / len(correct_pred_test)\n",
    "        running_test_acc += acc_test\n",
    "        \n",
    "        if index < 1:\n",
    "            total_pred = y_pred_test\n",
    "        else:\n",
    "            total_pred = torch.cat([total_pred, y_pred_test], dim=0, out=None)\n",
    "            \n",
    "        progress_bar_test.set_description(f'Test Loss: {running_test_loss/(index+1):.4f} Test accuracy: {(running_test_acc/(index+1))*100:.2f}%')\n",
    "        \n",
    "test_loss_hist.append(running_test_loss/(index+1))\n",
    "test_acc_hist.append(running_test_acc/(index+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9b646a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, precision_recall_fscore_support\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming y_true and y_pred are your true and predicted labels\n",
    "#y_true = [...]  # Replace with your actual labels\n",
    "#y_pred = [...]  # Replace with your model's predictions\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show()\n",
    "\n",
    "# Precision and Recall\n",
    "precision, recall, _, _ = precision_recall_fscore_support(y_true, y_pred, average='binary')\n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
